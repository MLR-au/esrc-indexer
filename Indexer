#!/usr/local/scholarly-python2/bin/python

import sys
import argparse
import logging
import ConfigParser
import os.path
from indexer.Timer import Timer
from indexer.Crawler import Crawler
from indexer.Transformer import Transformer
from indexer.Poster import Poster

if __name__ == "__main__":

    # read and check the options
    parser = argparse.ArgumentParser(description='eSRC Indexer')

    parser.add_argument('--config',   dest='config', required=True, help='The path to the default Indexer configuration.')
    parser.add_argument('--site',     dest='site',   required=True, help='The site to process.')

    parser.add_argument('--transform-document', dest='transform_document', default=None,
        help='Transform a single document and write the result to STDOUT.')
    parser.add_argument('--transform-document-type', dest='transform_document_type', choices = ['xml', 'html'], default=None,
        help='Transform a single document and write the result to STDOUT.')
    parser.add_argument('--post-document', dest='post_document', default=None,
        help='Post this document to SOLR.')

    parser.add_argument('--info', dest='info', action='store_true', help='Turn on informational messages')
    parser.add_argument('--debug', dest='debug', action='store_true', help='Turn on full debugging (includes --info)')

    args = parser.parse_args()

    # unless we specify otherwise
    if args.debug:
        logging.basicConfig(level=logging.DEBUG)

    if args.info:
        logging.basicConfig(level=logging.INFO)

    if not (args.debug and args.info):
        # just give us error messages
        logging.basicConfig(level=logging.ERROR)

    # get the logger
    log = logging.getLogger('INDEXER')

    # check the arguments
    if not os.path.exists(args.config):
        log.error("Does %s exist?" % args.config)
        sys.exit()

    if args.transform_document and not args.transform_document_type:
        log.error("If you specify a doc to transform via --transform-document, you must also state its type via --transform-document-type")
        sys.exit()

    def config_get(cfg, section, param):
        if cfg.has_section(section) and cfg.has_option(section, param):
            return cfg.get(section, param)
        else:
            return None

    log.debug("Indexing: %s" % args.site)

    # get the default configuration
    cfg = ConfigParser.SafeConfigParser()
    cfg.read(args.config)

    site_configuration = os.path.join(config_get(cfg, 'GENERAL', 'configs'), args.site)
    site_cache = os.path.join(config_get(cfg, 'GENERAL', 'cache_path'), args.site)
    default_transforms = config_get(cfg, 'GENERAL', 'transforms')
    log.debug("Configuration: %s" % site_configuration)
    log.debug("Cache path: %s" % site_cache)

    # then try to load the site specific config
    if not os.path.exists(site_configuration):
        log.error("Can't access %s" % site_configuration)
        sys.exit()

    # read in the site specific configuration and kick off the run
    cfg.read(site_configuration)

    ### CRAWL THE SOURCE FOLDER
    files_list = []
    if not args.transform_document:
        ### Only do the crawl if the user is not requesting to specifically
        ###  process a single file; this is usually testing
        input_folder = config_get(cfg, 'crawl', 'input')
        excludes = config_get(cfg, 'crawl', 'excludes')
        source = config_get(cfg, 'crawl', 'source').split(',')
        log.debug("Input folder for crawl: %s" % input_folder)
        log.debug("Excludes list: %s" % excludes)
        log.debug("Map to source: %s" % source)

        if input_folder is None:
            log.error("I think input folder is missing from the config: %s" % site_configuration)
            sys.exit()

        with Timer() as t:
            c = Crawler(input_folder, excludes, source)
            files_list = c.run()

    ### TRANSFORM THE CONTENT MARKED FOR INGESTION INTO SOLR
    output_folder = os.path.join(site_cache, 'post')
    transforms = config_get(cfg, 'transform', 'transforms')

    if not transforms:
        transforms = default_transforms
    else:
        transforms = [ transforms, default_transforms ]

    log.debug("Output folder for transforms: %s" % output_folder)
    log.debug("Transform search path: %s" % transforms)

    with Timer() as t:
        t = Transformer(files_list, output_folder, transforms)
        if args.transform_document is not None:
            t.process_document((args.transform_document, args.transform_document_type), debug=True)
        else:
            t.run()


    ### POST THE SOLR DOCUMENTS TO THE INDEX
    input_folder = os.path.join(site_cache, 'post')
    solr_service = config_get(cfg, 'post', 'index')

    log.debug("Content folder to be posted : %s" % input_folder)
    log.debug("Solr service: %s" % solr_service)

    with Timer() as t:
        p = Poster(input_folder, solr_service)



